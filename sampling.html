<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Sampling</title>
        <style type="text/css">
            tab0 { padding-right: 1em;}
            dummydeclaration { padding-left: 4em; } /* Firefox ignores first declaration for some reason */
            tab1 { padding-left: 2em; }
            tab2 { padding-left: 8em; }
            tab3 { padding-left: 12em; }

        </style>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/clean-blog.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
    <script src="js/jquery-min.js"></script>
    <script src="js/d3-min.js"></script>
    <script src="https://cdn.plot.ly/plotly-1.2.0.min.js"></script>


    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });
    </script>

    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand" href="index.html">Jaley Dholakiya</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="index.html">Home</a>
                    </li>
                    <li>
                        <a href="about.html">About</a>
                    </li>
                    <li>
                        <a href="contact.html">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="intro-header" style="background-image: url('img/post-bg.jpg')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="post-heading">
                        <h1>Sampling Algorithms</h1>
                        <h2 class="subheading">Key to Distribution's heart</h2>
                        <span class="meta">Posted by <a href="#">Jaley Dholakiya</a> on Mar 31, 2017</span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Post Content -->
    <article>
        <div class="contentainer">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <p align="justify">
                    <b>Statutory Warning : </b> <i>This is highly mathematical blog, hence only people have some familiarity with probability and Expectation should read it. Otherwise it can be a living nightmare</i>
                    </p>
                    <p align="justify">
                        In this blog, we are going to uncover ways of estimating a distribution via Sampling. This is "very" important blog for practical implementation of various ML Algorithms. We will start of with a short story about Monte Carlo 
                    </p>
                    <h2 class="subheading">Monte Carlo Approximation</h2>
                    <p align="justify">
                        <h3>Coin Tossing</h3>
                        What is the easiest way to find out the bias in coin ? in other words, whats $P(H)$? Think for a while . . . 
                    </p>
                    <p align="justify">
                        Simply toss the coin thousand times, and find the number of times head came divided by 1000. Thats it! Thats <b>Monte Carlo</b> for you guys. Here we are drawing 1000 random values from same coin tossing event. These 1000 values can be considered as one possible outcome of 1000 random variables which are drawn from the distribution. Its like  drawing $(X_1,X_2,\cdots X_{1000})$  from $P$ or probability distribution where $X_i$ is random variable.so $(x_1,x_2,\cdots x_{1000})$ is one possibe outcome of drawing, something like $(H,T,\cdots T)$.
                    </p>
                    <div style="background-color:#ddeeee;padding:24px;margin: 21px;color: #666666">
                        <b>Mathematical Definition of Monte-Carlo Approximation</b><br/>
                        <p align="justify">
                        If you draw N random numbers $(X_1,X_2,\cdots X_{N})$  from a probability distribution $P$ which are IID's(Independent and Identically distributed ), then the bellow equation holds true.
                        $$\lim_{N\rightarrow \infty} ||E(f(X))-\frac{1}{N}\sum\limits_{i=0}^Nf(X_i)|| = 0 $$                        
                        </p>
                        <b>Mathematical Definition of Monte-Carlo Integration</b><br/>
                        If $X_1,X_2,\cdots$ are sampled from a distribution $P$, then we can approximate  integratation of a function over such distribution as shown bellow :  
                        $$\int_Xf(X)p(x)dx \approx \frac{1}{N}\sum_{i=0}^{N}f(X_i)$$
                    </div>
                    <p align="justify">
                    The goal in the above equation is to estimate $E(f(X))$ for some function f. Now computing expectation is super easy for simple random variable like binomial with 2 trials $(P=Bin(2))$. If you do it monte-carlo way, you will throw a pair of coins 100's of times and estimate function for each of the outcome and average it out. If you do the same by standard approch, it looks something like this :   $$E(f(X))=\frac{1}{3}\Big( P(\#H=0)f(0)+P(\#H=1)f(1)+P(\#H=2)f(2) \Big)$$ But let us say, if we have 10 dice throwing experiment. Can you tell me the number of points where we have to estimate value of f? It has to be on $6^{10}$ points or 60,466,176 points. In other words estimating function on a probability space becomes more and more difficult when X is of higher dimension and/or has large number of possible outcomes. This is the main reason why monte-carlo based methods are needed, where we sample a lot of random variables from Distribution($X_i \sim Bin(3)$) and get average estimation of its value.
                    </p>
                    <h2 class="subheading">Importance Sampling</h2>
                    <div style="background-color:#eeeeee;padding:24px;margin: 21px;color: #666666">
                        <b>Limitations of Monte Carlo</b><br/>
                        <p align="justify">
                        Let us consider a case where my functions is defined as bellow where $X \sim \mathcal{N}(\mu =0,\,\sigma ^{2}=1) $: 
                                $$ 
                                f(x) =
                                \left\{
                                    \begin{array}{ll}
                                        0  & \mbox{if } x < 3 \\
                                        1 & \mbox{if } x > 3 
                                    \end{array}
                                \right. \hspace{2 cm} 
                                p(x) = \cfrac{1}{\sqrt{2\pi}}e^{-\cfrac{x^2}{2}}
                                 $$
                        Do you see anything strange in the above case? The regions where the pdf(probability density function) of the domain is high, you can see that the function's value is 0, and conversely, the regions where the function's value is high, the pdf is close to 0. Now if you try do monte carlo estimation using 100 points, its definitely gonna give you not so correct answer. You may need to conduct the experiment, 10000 times to get good enough estimate. But isn't it tedious? There will come a point, where you will start wondering, if there is a better way to get the expectation. Because I can't always generate soo many samples for estimation. Thats what a lot of mathematicians thought and we now have Importance Sampling.
                        </p>
                    </div>
                    <p align="justify">
                    <i>"If only, we could have more samples where the function's value is high."</i> What if we could sample from some other distribution? Thats exactly what lead to Importance sampling where we sample from some other distribution, where the function's value is high for substantial fraction of samples. Let us say, this new distribution is $q(x)$. It is generally chosen to be wide in varience, so that it overlaps with regions where the function is high and also with the regions where the function is not high. It is best to cover regions where the $p(x)$ was also dense.(which is around 0).
                    </p>
                    <img src="img/importanceSampling.png" class="img-responsive center-block" style='height: 100%; width: 60%; object-fit: contain' />                    
                    <p align="justify">
                    Hence we choose a fake distribution, $q(x)$ as $\mathcal{N}(\mu =1,\,\sigma ^{2}=4) $ instead of $p(x)$ which is $\mathcal{N}(\mu =0,\,\sigma ^{2}=1) $. This distribution is called fake, because that's not how actual distribution of samples are. Now comes the important part, as we are not sampling from p(x), we will have to weight each sample differently. Intuitively, weightage of points after 3 should be less because they are very less probable in actual distribution. This weightage is called importance weight.
                    </p>
                    <p align="justify">
                    Hold on to what you have read in the previous paragraph, because now we are going to find out the importance weight mathematically. A quick recap of difference between standard way and monte carlo way of estimation is essential before we proceed.
                    </p>
                    <div class="container">
                        <div class="row">
                            <div class="col-md-6" style="background-color: #eeeedd;padding: 25px;margin-right: 35px;margin-bottom: 35px;height: 180px">
                                <b>Exact Solution (Continuous)</b> <br/>
                                $$ E(f(X))=\int_{-\infty}^{\infty}  f(x)p(x)dx$$
                            </div>
                             <div class="col-md-5" style="background-color: #eeeedd;padding: 25px;margin-left: 35px;margin-bottom: 35px;height: 180px">
                                <b>Monte Carlo Approximation (Continuous)</b> <br/>
                                $$ E(f(X))=\frac{1}{N}\sum_{i=1}^{N}f(X_i)$$
                                <div id="tester"></div>
                           </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6" style="background-color: #eeeedd;padding: 25px;margin-right: 35px;margin-bottom: 35px;height: 180px">
                                <b>Exact Solution (Discrete)</b> <br/>
                                $$ E(f(X))=\sum\limits_{x=-\infty}^{\infty}  f(x)p(x) $$
                            </div>
                             <div class="col-md-5" style="background-color: #eeeedd;padding: 25px;margin-left: 35px;margin-bottom: 35px;height: 180px">
                                <b>Monte Carlo Approximation (Discrete)</b> <br/>
                                $$ E(f(X))=\frac{1}{N}\sum_{i=1}^{N}f(X_i)$$
                                <div id="tester"></div>
                           </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6" style="background-color: #eeeedd;padding: 25px;margin-right: 35px;margin-bottom: 35px;height: 250px">
                                <b>Exact Solution (Continuous)</b> <br/>
                                $$ E(f(X))=\int_{-\infty}^{\infty}  \overbrace{\left(f(x)\frac{p(x)}{q(x)}\right)}^{\mbox{new function}}q(x)dx$$
                            </div>
                             <div class="col-md-5" style="background-color: #eeeedd;padding: 25px;margin-left: 35px;margin-bottom: 35px;height: 250px">
                                <b>Importance Sampling (Continuous)</b> <br/>
                                $$ E(f(X))=\frac{1}{N}\sum_{i=1}^{N}f(X_i)*\overbrace{\frac{p(X_i)}{q(X_i)}}^{\mbox{imp w's}}$$
                                where $X_i \sim \mathcal{N}(\mu=1,\sigma^2=4) $ a.k.a $q(X)$
                                <div id="tester"></div>
                           </div>
                        </div>
                    </div> 
                    <p align="justify">If you observe the bottom-right block of equation, you will observe that $X_i$ are sampled from $q(X)$. Which means a lot of them will fall beyond 3 mark. But thier contribution will be weighted(suppressed) by importance weight or ($p(X_i)/q(X_i)$). So it is called Importance sampling because we are not sampling according to actual distribution (p(X)) , rather we are sampling according to q(X) and then making up for the distortion by multiplying the function value by importance weight(p/q).</p>
                    <p align="justify">
                    In terms of variance, you will observe that the variance of the newly sampled points will be lesser the previously sampled variance.
                    </p>
                    <div class="container">
                        <div class="row">
                            <div class="col-md-5" style="background-color: #eeeedd;padding: 5px;margin-right: 35px;margin-bottom: 35px;">
                                <b>Old Variance</b> <br/>
                                <!-- $$ Var(f(X))=\int_{-\infty}^{\infty}  [f(x)-E(f(X))]^2p(x)dx$$ -->
                                $Var(f(X))$ via Monte-Carlo Sampling : $1.3\times10^{-5}$
                            </div>
                             <div class="col-md-6" style="background-color: #eeeedd;padding: 5px;margin-left: 35px;margin-bottom: 35px;">
                                <b>New Variance </b> <br/>
                                <!-- $$ Var(f(X))=\int_{-\infty}^{\infty}  \left[f(x)\cfrac{p(x)}{q(x)}-E\left(f(X)\cfrac{p(X)}{q(X)}\right)\right]^2q(x)dx$$ -->
                                $Var(f(X))$ via Importance Sampling : $9.5\times10^{-8}$
                           </div>
                        </div>
                    </div>
                <p align="justify">The above variance is calculated by taking 1000 samples of 100 size, and for each you find out the mean. Now you find out the Variance based on variation in the expected value of sample(calculated for each 100 size sample) from actual exepected value of the function over the domain. This is calcuated for 1000 expected values obtained for each sample.</p>
                <h2 class="subheading">Inverse Transform Sampling a.k.a Smirnov Tranform</h2>
                <p align="justify"> Let us say, we conducted an experiment on longitivity of 1500 mosquitoes, and found out that 500 die within (1/100)th of a day. Another 500 die between (1/100)th and (1/10)th of the day. Remaining 500 die in rest of the period. Now the thing, I want to generate a random number with such probability for simulation experiments. The problem is that I have only uniform density generator available. How do I generate such distribution? Think about it for a while.</p>
                <h3><i>A meter's rod solves it all</i></h3>
                <p align="justify"> 
                    While thinking about solution for generating such distribution, I ended up going to my garage, where I saw  my dad doing his daily car cleaning chores of the day.I asked him this burning question that I was having. He being mechenical engineer is wired to think in physical terms. So he took out the 1 meter rod  and marker from the inventory box. He then marked 33 cm mark in the meter rod as $(1/100)^{th}$ and  66 cm mark as $(1/10)^{th}$. Now he told me as follow : <br/><br/>
                    <i><b>Dad : </b> Ask your uniform random number generator to spit out some numbers between 0 and 1 </i> <br/>
                    <i><b>Me  : </b> Ok pops, it says 0.2,0.5,0.9 </i> <br/>
                    <i><b>Dad : </b> Wa, Wa, Wait, Slow down</i> <br/>
                </p>
                <img src="img/mosquitoscale.png" class="img-responsive center-block" style='height: 100%; width: 60%; object-fit: contain' />
                <p align="justify"> He now used a chalk to write seperate set of markings in the right of the scale, which is uniformly increasing from 0 to 0.01 untill it reaches 33 cm mark on scale, then it uniformly increases from 0.01 to 0.1 untill it reaches 66 cm mark, again it keeps increasing from 0.1 to 1 untill it hits 1 meter mark. He told this named this new scale as Mosquito Scale. He asked me to note down the numbers coming mosquito scale against the numbers which are spited out by random number generator and queried by the meter scale. In short output is mosquito scale, input in meter scale. Thats it!, bazinga, I had my mosquite life simulator!!!</p>
                <p align="justify"> In short, my dad discovered Smirnov sampling in his own mechenical way. Lets look at what has he done here in a more mathematical definition. Before we bunge into definition, have look at the intuition. </p> 
                <h3>Intuition</h3>
                    <p align="justify">
                    <i>What is more probable should get more space</i><br/>
                    If you are showing ads to a TV user, and each ad has some probability of generating revenue. The revenue it gives should be proportional to time allocated for that ad. Thats classic smirnov problem for you guys. Its like stretching out more probable(of generating revenue) ads, and shrinking out less probable ones. So that now they are all equally probable. It is like going towards uniform distribution, by stretching/shrinking down more and less probables to get it all flat. Think for a while, cause its super-important concept and a visualization. What if I say, that it seems like Inverse? Because we are flattening out the probabilities? Moving from $CDF[0,1]$ to $U[0,1]$. Well thats the intuition for you readers. 
                    In Mosquito case, we need to give 33.33% bandwidth for [0,0.01] as its probability is 1/3. Similarly next 33% bandwidth for interval [0.01,0.1] pushing us to 66% mark and remaining 33% for [0.1,1]. That sounds familiar, cause its cumulative probability distribution which we are evening out. In the process of evening the range out, the domain gets transformed and becomes the CDF range points. Range becoming domain is nothing but inverse of CDF, and thats exactly what Smirnov Transform is.
                    </p>
                <div style="background-color:#ddeeee;padding:24px;margin: 21px;color: #666666">
                    <b>Mathematical Definition</b><br/>
                    Let us consider p as some probabilty density function and P,its cumulative distribution function s.t $P:\mathcal{R}\rightarrow [0,1] $, then  $P^{-1}(x)$ where $x\in \mathcal{U}[0,1]$  will have pdf(density.func) as p.
                </div>

                <h2 class="subheading">Rejection Sampling</h2>
                <p align="justify"> Rejection Sampling - name says it all. Its kind of sampling where we reject samples, based on some strategy.This kind of sampling in very useful, if you don't know the exact distribution  or it is very difficult to compute, but know approximate shape of the distribution(or can find another distribution closely enveloping it). But lets consider simplest example for rejection sampling.</p>
                <p align="justify"> Let p(x)=$\mathcal{N}(0,1)$(Normal distr) be the pdf(probability density function) of interest. We first find out rectangle kg(x) which boxes it down. Such rectangle spans from -6 to 6 and has height $1/\sqrt{2\pi}$. Here $k = 12/\sqrt{2\pi}$ which gets multiplied with $\mathcal{U}(-6,6)$(uniform distr) with height $1/12$. Now here is the stratagy </p>
                <img src="img/rejectionsampling.png" class="img-responsive center-block" style='height: 100%; width: 60%; object-fit: contain' />
                    <div class="container">
                        <div class="row">
                            <div class="col-md-12" style="background-color: #eeeedd;padding: 5px;margin-right: 35px;margin-bottom: 35px;">
                                <h3>Algorithm for rejection sampling</h3>
                                <!-- $$ Var(f(X))=\int_{-\infty}^{\infty}  [f(x)-E(f(X))]^2p(x)dx$$ -->
                                <i>
                                    <b><tab0><small>1.</small></tab0></b>Sample a random value u from  $\mathcal{U}(0,1)$. <br/>
                                    <b><tab0><small>2.</small></tab0></b>Sample a random value $x_1$ from $g(x)$. <br/>
                                    <b><tab0><small>3.</small></tab0></b><b>for</b> i in 1:N<br/>
                                    <b><tab0><small>4.</small></tab0></b><tab1><b>if</b> $u*g(x_i)\leq p(x)$ <br/></tab1>
                                    <b><tab0><small>5.</small></tab0></b><tab1><b>then</b> accept $x_i$ <br/></tab1>
                                    <b><tab0><small>6.</small></tab0></b><tab1><b>else</b> reject $x_i$ <br/></tab1>
                                    <b><tab0><small>7.</small></tab0></b><tab1>Sample u, $x_{i+1}$ from $\mathcal{U}(0,1)$ and $g(x)$ respectively <br/></tab1>


                                </i>
                            </div>
                        </div>
                    </div>                
                <p align="justify"> Note that g(x) is <b>NOT</b> a pdf, rather a <i>scaled</i> pdf(prob.density.func). It is scaled in such a way that $\forall x\in \mathcal{D}p(x)$, $\min\limits_{k} kg_{N}(x) \geq p(x)$ where $g_{N}(x)$ is actual pdf(i.e normalized). In other words g(x) is always greater than or equal to p(x) in its domain, and touches it at atleast one point.</p>
                <p align="justify">Why does this stratagy work? For that I will ask you a bunch of questions and answer will lead us to a greater understanding</p>

                <p align="justify">
                    
                    <tab0><b>Q.</b></tab0>What is the probabilty by with we are sampling x ? <br/>
                    <tab0><b>A.</b></tab0>$g_N(x)$<br/><br/>
                    <tab0><b>Q.</b></tab0>What is the probabilty of a particular $x$,i.e $x_*$ getting accepted after selection <br/>
                    <tab0><b>A.</b></tab0>$p(x_*)/g(x_*)$<br/><br/>
                    <tab0><b>Q.</b></tab0>What is the overall probabilty of x getting selected in general? In other words, What is the probability distribution of x? <br/>
                    <tab0><b>A.</b></tab0>$Normalized(g_N(x)*p(x)/g(x))=\frac{p(x)/k}{\int (p(x)/k) dx}=\cfrac{p(x)/k}{1/k}=p(x)$<br/>
                </p>

                <p align="justify">If you think about the questions, the intuition behind the stratagy will be right in front of you. Simply speaking, we are selecting an x from distribution of $g_N(x)$ and then accepting it with probability $p(x)/g(x)$. That means in some way, we are generating samples from distribution of p(x)</p>
                <p align="justify"> Use discretion in selecting g(x). If it's shape is too much different from p(x), then a lot of samples will be rejected. Fraction of total rejections = Area of region between f(x) and g(x) divided by total area of g(x).
                </p>
                <h2 class="subheading">Sneak peak into Bayesian Inference</h2>
                <p align="justify">
                    Lets say you see you little brother enter your house totally drenched in water. You want to use Bayesian Inference to determine if there was actually any rain. In this scenario, you want to find the probability of raining outside given that your brother is wet. This is also called posterior in ML Terms. </p>
                    <p align="justify">
                    Any thing post the observed event (whose probability are generally provided), "post condition=wetness/ post apocalypse" which can be possible cause to it, can be termed as posterior event, and its probability can be termed as <b>posterior probability</b>. <b>Likelihood Probability, </b>P(wet|rain) is  possibility(probability) of event to be a cause the apocalype/wetness.In another cryptic way I can say , "Suppose causal event(rain or bucket) occurs, whats probability of causation to lead to to the actual event". Its like P(smoke|volcano) is 0.98, which means lets suppose volcano is cause of smoke, then probabity of eruption translating to smoke is 0.98.</p>
                    <p align="justify"> It can also be seen as turning the posterior upside down in terms of conditional probability. In our example, P(rain|wet) is posterior, P(wet|rain), P(wet|bucket from top) is likelihood, and P(rain) is prior. <b>Prior probability</b> is nothing but information about independent probability of the conditional we are evaluating. So in posterior, if you remove the pre-condition(P(rain|<strike>wet</strike>)), it becomes, prior probability i.e P(rain).
                    </p>                    
                    <p align="justify">
                     The last but not the least, is the normalizing denominator or <b>partition function</b>. It is P(wet) which is broken down(partioned) into all possible sample events and their priors. Here it is P(wet|rain)*P(rain)+P(wet|bucket)*P(bucket)+P(wet|rest)*P(rest). Please Note that here, the causes of "wetness" are partioned by possible prior events(which could have lead to "wetness"). This  includes (rain,bucket,rest).Note that P(rain)+P(bucket)+P(rest)=1 also holds true.
                     $$\overbrace{P(rain|wet)}^{posterior} = \cfrac{\overbrace{P(rain)}^{prior}*\overbrace{P(wet|rain)}^{likelihood}}{\underbrace{P(wet)}_{partition}}$$
                     Also partition function can be broken into priors of causal events and thier likelihoods.
                     $$\overbrace{P(wet)}^{partition}=\underbrace{\overbrace{P(rain)}^{prior(E1)}\overbrace{P(wet|rain)}^{likelihood(E1)}}_{\text{if suspected cause is rain}}+\underbrace{\overbrace{P(bucket)}^{prior(E2)}\overbrace{P(wet|bucket)}^{likelihood(E2)}}_{\text{if suspected cause is bucket}}+\underbrace{\overbrace{P(rest)}^{prior(E3)}\overbrace{P(wet|rest)}^{likelihood(E3)}}_{\text{if suspected cause is unknown}}$$
                </p>
                    <div style="background-color:#ddeeee;padding:24px;margin: 21px;color: #666666">
                        <b>Mathematical Definition</b><br/>
                        Let X be an event which can be caused by $Y\in\left\{Y_1,Y_2 \cdots Y_N\right\}$ causes. Here each $Y_i$ is a possible cause for X. Then, probability that "$Y_*$ caused X" is given by bellow equation : 
                        <p align="justify">
                        $$P(Y_*|X) = \cfrac{P(Y_*)*P(X|Y_*)}{\sum\limits_{i=0}^{N}P(X|Y_i)*P(Y_i)}$$
                        In continuous domain, it can be written as bellow : 
                        $$P(Y_*|X) = \cfrac{P(Y_*)*P(X|Y_*)}{\int\limits_{\theta =-\infty}^{\infty} P(X|Y_{\theta})*P(Y_{\theta })dY_{\theta }}$$
                        </p>
                    </div>
                    <div class="container">
                        <div class="row">
                            <div class="col-md-6" >
                                <b>Example based Venn Diagram</b> <br/><br/>
                                <img src="img/venndiagram.png" class="img-rounded" style='height: 100%; width: 100%; object-fit: contain' />
                                <br/><br/>
                                <tab0><b>Posterior</b></tab0>$P(rain|wet)$<br/>
                                <tab0><b>Likelihood</b></tab0>$P(wet|rain)$<br/>
                                <tab0><b>Partition Function</b></tab0>$P(wet)$<br/>
                                <tab0><b>Expanded Partition </b></tab0>$\sum\limits_{t}P(wet|t)P(t)$<br/>
                                <tab0><b>Partition Params(t)</b></tab0>$rain$,$bucket$,$rest$<br/>

                            </div>
                             <div class="col-md-6">
                                <b>Generallized Venn Diagram</b> <br/><br/>
                                <img src="img/venndiagram2.png" class="img-rounded" style='height: 100%; width: 100%; object-fit: contain' />
                                <br/><br/><br/>
                                <tab0><b>Posterior</b></tab0>$P(t_1|x)$<br/>
                                <tab0><b>Likelihood</b></tab0>$P(x|t_1)$<br/>
                                <tab0><b>Partition Function</b></tab0>$P(x)$<br/>
                                <tab0><b>Expanded Partition </b></tab0>$\sum\limits_{t}P(x|t)P(t)$<br/>
                                <tab0><b>Partition Params(t)</b></tab0>$t_1$,$t_2$,$t_3$<br/>

                           </div>
                        </div>
                    </div> 
                    <h3>Practical Bayesian Estimate</h3>
                    All this philosophical explainations of rain and bucket are of NO use, if you don't understand how bayesian estimates are used by datascientists in day-to-day work.<br/>
                    Let us say, I know the distribution of data ($x$) is normal(gaussian). I just want to know the mean ($\mu$) of this distribution given the data points. Our big assumption is that only mean of the best fitting distribution is to be known, varience is already known/fixed.
                    Now how would you find it out? You can very easily say that $E(x)$ is the best value to be assigned to $\mu$ parameter. But here is the twist. Lets say you know the prior distribution of the data from internet, and you need to somehow take this into account. How will you do that? Create a grid of possible $mu$ values. For each $\mu$ value, i.e $\mu_i$, Find out the value of term $Prior(\mu_i)*Likelihood(x|\mu_i)$ for each $\mu_i$ where x is nothing but 100 data points and $Likelihood(x|\mu_i)$ is given by 
                    
                    $$Likelihood(x|\mu_i)=\prod\limits_{i=0}^{99} Likelihood(x_i|\mu_i)$$

                    Note, $Prior(\mu_i)$ is nothing but probability of parameters, which is nothing but mean here. So $Prior(x=\mu_i)$ will give probability of distribution's mean having certain value. It emits a number telling probability of having such mean(parameter) in the first place irrespective of likelihood. If we have to check posterior(without partion) for $\mu=0.3$ and x=[0,0.5,2], I have to evaluate $Prior(0.3)*Likelihood(x|\mu=0.3)$. Assume $Prior\sim \mathcal{N}(0,1)$ and Likelihood to be $\mathcal{N}(\mu_i,2)$. For these distributions, the handpicked $\mu_i=0.3$ (one point from mesh grid of all possible $\mu$'s) ,our posterior will be proportional to 
                    $$\underbrace{Posterior(\mu_i=0.3|x)}_{shittynumber} \propto \underbrace{g_{(0,1)}(0.3)}_{prior}.\underbrace{g_{(0.3,2)}(0).g_{(0.3,2)}(0.5).g_{(0.3,2)}(2)}_{likelihood}$$
                    <br/>
                    Note that here $$g_{(\mu,\sigma)}(x)=\cfrac{1}{\sqrt{2\pi\sigma^2}}e^{\cfrac{-(x-\mu)^2}{2\sigma^2}}$$. Now we evaluate the above expression to get this 'shitty number' for other points of grid(apart from 0.3), ie $\mu_i\in[-1,-0.99\cdots 0.99,1]$. We then select the shittiest parameter i.e $\underset{\mu_i}{\arg \max}shittynumber$. It means that over that grid, the selected $\mu_i=\mu_*$ gives highest value of $\propto Posterior(\mu_*|x)$. And thankfully, the proportionality constant is same for all the points in the grid which is nothing but $\cfrac{1}{Partition(x)}$. Hence we discount its hefty calculation, getting rid of all the difficulties in evaluating partition function.
                    <br/>
                    To summarize, we are trying to estimate a parameter, given that we know its prior distribution. Had we not known prior distribution, we could have simply considered $E(x)$ or to be accurate, $\underset{\mu_i}{\arg \max}\prod\limits_{j=0}^{N-1} g_{(\mu_i,2)}(x_j)$. But now because of prior, we find out the $\mu_i$ resulting in highest $prior*posterior$ value.


                    <h2>From Independent Trials to Markov Chain</h2>
                    <p align="justify">
                    Let us say you are given two tasks. First is to toss a coin, and the second is to roll a dice. Do you think, that outcomes of coin will affect outcomes of dice ? No, right! Thats why we call such events independent. But lets say you are given a jar of toffees. It contains strawberry flavored and  dark chocolate flavored toffee. But unlike coin and dice, where one outcome is independent of the other outcome, we have 90% tendency to select the other flavored toffee. Which means events are not independent. I will not want to eat same toffee two times in a row. To model such an event, we require understanding of sequence.</p>
                    <div class="container">
                        <div class="row">
                            <div class="col-md-5" style="padding: 25px;margin-right: 35px;margin-bottom: 35px">
                                <b>Example 1</b> <br/>
                                <img src="img/statespace.png" class="img-rounded" style='height: 100%; width: 100%; object-fit: contain' />
                                <tab0><b>1.</b></tab0>P(stay in same state) = 0.1<br/>
                                <tab0><b>2.</b></tab0>P(change to next state) = 0.9<br/>
                            </div>
                             <div class="col-md-5" style="padding: 25px;margin-left: 35px;margin-bottom: 35px">
                                <b>Example 2</b> <br/>
                                <img src="img/statespace2.png" class="img-rounded" style='height: 100%; width: 100%; object-fit: contain' />
                                <tab0><b>1.</b></tab0>P(stay in same state) = 0.9<br/>
                                <tab0><b>2.</b></tab0>P(change to next state) = 0.1<br/>

                           </div>
                        </div>
                    </div> 

                    <h3>Markovian Property and Conditional Independence</h3>
                    Let us consider 5 events as shown in the figure, where A depends on B, B depends on C,D,E. Now, Markovian property states that $P(A|B,C,D,E)$ is $P(A|B)$. It means A is conditionally independent of C,D,E given that we know $P(A|B)$. In a simple linear chain of events, happening sequencially, it states that future sequence is independent of past sequence, provided we know present event.
                    <img src="img/conditionalIndependence.png" class="img-responsive center-block" style='height: 100%; width: 30%; object-fit: contain' />
                    <h2> MCMC aka Markov Chain Monte Carlo </h2>
                    We studied in the previous section how we try to estimate the posterior distribution by applying bayes theoram. But it can be pretty tedious because of the bellow reasons.<br/>
                    <tab0><b>1.</b></tab0>Partition Function is too difficult to estimate <br/>
                    <tab0><b>2.</b></tab0>Joint Likelihood is difficult to replicate.(same problem as in importance sampling)<br/><br/>
                    <div style="background-color:#ddeeee;padding:24px;margin: 21px;color: #666666">
                    <h3>Motivation for MCMC</h3>
                    Imagine a football ground and I need to estimate the distribution of wet regions in field. Now, comparing to large football field, the probability of wet regions is very less. If you use traditional monte carlo distribution estimation, it will fail miserably, because there are very high chances that the monte carlo samples do not fall into the wet regions. But what about Importance sampling? Even that will fail miserably because choice of the fake/auxillary distribution which we use for sampling can be cumborsome. So what is the sollution? The solution lies in MCMC.<br/>
                    The idea for MCMC is that start from a random sample and keep moving untill you find region of reasonably good probability. You can visualize it as climbing a hill. Now you have a choice, either you can accept a new sample around the hilltop and probably towards another hilltop, or reject it. This is because, we have a vague idea that wet regions are connected in some ways. In mathematical sense, we become oblivious/ ignorant of the vast regions of insignificant probability and only concentrate on the caravan of high probability regions which are loosely connected. So we move in form of a markov chain (a chain of samples), always deciding about going ahead or staying back(reject the new sample) based on a <b>deciding factor</b>. Now the intuition is that such group of samples will best describe the distribution.<br/>
                    Do note that unlike importance or rejection sampling you don't need any specific distribution to start off with.
                    </div>
                    <img src="img/MCRobot.png" class="img-responsive center-block" style='height: 100%; width: 60%; object-fit: contain' />
                    <h3>Simple Case - Gaussian Prior, Gaussian Likelihood, Gaussian Posterior </h3>
                    <p align="justify">
                    Let us consider 
                    </p>





                <h3>References</h3>
                <i><a htref="http://astrostatistics.psu.edu/su14/lectures/cisewski_is.pdf">1. Importance Sampling, Jessi Cisewski, CMU, June 2014</a></i><br/>
                <i><a href="https://www.youtube.com/user/mathematicalmonk">2. Mathematical Monk Youtube channel, Lecture 17-18</a></i><br/>
                <i><a href="https://www.datascience.com/blog/introduction-to-bayesian-inference-learn-data-science-tutorials">3. Aaron Kramer, Introduction to Bayesian Inference</a></i>
                 <i><a href="http://carrot.mcb.uconn.edu/~olgazh/bioinf2010/">4. MCMC Blue Hilltop image is taken from MCRobot Course Material</a></i>               
                </div>


            </div>
        </div>
    </article>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>
                    <!--p class="copyright text-muted">Copyright &copy; Your Website 2016</p-->
                </div>
            </div>
        </div>
    </footer>

<div id="disqus_thread"></div>
<script>


var disqus_config = function () {
this.page.url = 'https://jaleyhd.github.io/sampling.html';  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = '4April2017Sampling'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://jaleydholakiya.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                            

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/clean-blog.min.js"></script>
    <script src="js/vis/blog1.js"></script>

<script id="dsq-count-scr" src="//EXAMPLE.disqus.com/count.js" async></script>
</body>

</html>
